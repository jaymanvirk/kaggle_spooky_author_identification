{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jaymanvirk/fine-tuning-logreg-rf-nb-svm-and-xgboost?scriptVersionId=146555550\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Spooky Author Identification: Fine-tuning Logistic Regression, Random Forest, Multinomial Naive Bayes, SVM and XGBoost","metadata":{}},{"cell_type":"markdown","source":"**Jay Manvirk (Ivan Loginov)**<br/>\nUniversity of Colorado, Boulder<br/>\njay.manvirk@gmail.com","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n\n1. [Abstract](#chapter_1)\n2. [Introduction](#chapter_2)\n3. [Libraries and raw data](#chapter_3)\n    - 3.1 [Libraries](#chapter_3_1)\n    - 3.2 [Raw data](#chapter_3_2)\n4. [Exploratory data analysis](#chapter_4)\n    - 4.1 [Short datasets summary](#chapter_4_1)\n    - 4.2 [Number of records per author](#chapter_4_2)\n    - 4.3 [Word frequencies per author](#chapter_4_3)\n5. [Data preprocessing](#chapter_5)\n    - 5.1 [Text cleaning](#chapter_5_1)\n    - 5.2 [TF-IDF vectorization](#chapter_5_2)\n    - 5.3 [Dimensionality reduction](#chapter_5_3)\n    - 5.4 [Standardization](#chapter_5_4)\n    - 5.5 [Label encoding](#chapter_5_5)\n6. [Model architecture](#chapter_6)\n    - 6.1 [Logistic Regression](#chapter_6_1)\n    - 6.2 [Random Forest](#chapter_6_2)\n    - 6.3 [Multinomial Naive Bayes](#chapter_6_3)\n    - 6.4 [SVM](#chapter_6_4)\n    - 6.5 [XGBoost](#chapter_6_5)\n7. [Model results](#chapter_7)\n8. [Submission results](#chapter_8)\n9. [Conclusion](#chapter_9)\n10. [References](#chapter_10)","metadata":{}},{"cell_type":"markdown","source":"# 1. Abstract <a class=\"anchor\" id=\"chapter_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"In this study we explore the fine-tuning of various machine learning algorithms: Logistic Regression, Random Forest, Multinomial Naive Bayes, Support Vector Machine (SVM) and XGBoost, for the task of author classification based on short textual excerpts. Our objective is to identify the optimal configurations that minimize logloss.\n\nAll the experiments conducted in this study were based on the dataset comprising text from works of fiction written by renowned authors of the public domain: Edgar Allan Poe, H.P. Lovecraft and Mary Shelley. Every algorithm undergoes fine-tuning via grid search and cross-validation within limited computational resources, ensuring a detailed exploration of the hyperparameter space.","metadata":{}},{"cell_type":"markdown","source":"# 2. Introduction <a class=\"anchor\" id=\"chapter_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"This study aims to optimize several machine learning algorithms:\n* Logistic Regression\n* Random Forest\n* Multinomial Naive Bayes\n* SVM\n* XGBoost.\n\nunder moderate computational constraints. The goal is to identify configurations that minimize log loss in the author classification problem while ensuring computational efficiency.\n\nThe dataset is sourced from Kaggle for both training and submission purposes and can be accessed by following the link in the References section. It consists of:\n* trainig data: 19 579 texts\n* testing data: 8 392 texts\n* unique authors: 3 (Edgar Allan Poe, Howard P. Lovecraft, Mary W. Shelley)\n* text language: English\n* training text average size: ~149 characters\n* testing text average size: ~148 characters\n\nTo attain our objective, we will navigate through the following sections:\n* **Exploratory data analysis:**<br/>\nShort dasets summary: examining the dataset's size, structure, and the average length of text will guide us in determining whether further parallelization of computations is necessary.<br/>\nNumber of records per author: understanding the distribution of records per author provides helps identify the need for techniques such as down/up-sampling and additional class balancing tuning in our models<br/>\nWord frequencies per author: this analysis enables us to identify noise in the data which might hinder the accuracy of our models\n* **Data preprocessing:**<br/>\nText cleaning: based on the insights from EDA, we'll eliminate words that don't contribute useful information about the author's style<br/>\nTF-IDF vectorization: we'll convert texts into a word-weight matrix using TF-IDF for later use in the model training to achieve lower log loss<br/>\nStandardization: we'll introduce transformation of our word-weights to a consistent range to see whether this method enhances the convergence speed of gradient-based optimizers<br/>\nLabel encoding: as raw string labels cannot be processed by some algorithms, we will encode them into integers\n* **Model architecture:**<br/>\nIn this section, we will introduce configurations for Logistic Regression, Random Forest, Multinomial Naive Bayes, SVM, and XGBoost. The provided selection of hyperparameters will be utilized by GridSearchCV to identify the best set for our models.\n* **Model results:**<br/>\nWe will present a summarizing table displaying the model results, including every specified set of parameters from the previous section. Additionally, we will provide explanations for these results, offering insights into our model performance.","metadata":{}},{"cell_type":"markdown","source":"# 3. Libraries and data <a class=\"anchor\" id=\"chapter_3\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Libraries <a class=\"anchor\" id=\"chapter_3_1\"></a>","metadata":{}},{"cell_type":"code","source":"# basics\nimport os\nimport time\nimport numpy as np\n\n# EDA\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data preprocessing\nimport re\nimport spacy\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom concurrent.futures import ProcessPoolExecutor\nfrom sklearn.decomposition import TruncatedSVD\n\n# Model architecture\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nimport xgboost as xgb\n\n# Hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2023-10-13T20:05:49.675002Z","iopub.execute_input":"2023-10-13T20:05:49.675439Z","iopub.status.idle":"2023-10-13T20:05:49.683072Z","shell.execute_reply.started":"2023-10-13T20:05:49.675407Z","shell.execute_reply":"2023-10-13T20:05:49.682007Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Raw Data <a class=\"anchor\" id=\"chapter_3_2\"></a>","metadata":{}},{"cell_type":"code","source":"# Print list of files and directories in folder\nlist_l = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        list_l.append(os.path.join(dirname, filename))\nlist_l","metadata":{"execution":{"iopub.status.busy":"2023-10-13T21:58:43.514885Z","iopub.execute_input":"2023-10-13T21:58:43.515319Z","iopub.status.idle":"2023-10-13T21:58:43.532274Z","shell.execute_reply.started":"2023-10-13T21:58:43.515289Z","shell.execute_reply":"2023-10-13T21:58:43.531026Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/spooky-author-identification/train.zip',\n '/kaggle/input/spooky-author-identification/test.zip',\n '/kaggle/input/spooky-author-identification/sample_submission.zip']"},"metadata":{}}]},{"cell_type":"code","source":"# Set datasets\ntrain_data = pd.read_csv(list_l[0])\ntest_data = pd.read_csv(list_l[1])\nsample_data = pd.read_csv(list_l[2])","metadata":{"execution":{"iopub.status.busy":"2023-10-13T21:58:45.084927Z","iopub.execute_input":"2023-10-13T21:58:45.085826Z","iopub.status.idle":"2023-10-13T21:58:45.229043Z","shell.execute_reply.started":"2023-10-13T21:58:45.085761Z","shell.execute_reply":"2023-10-13T21:58:45.22811Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# Cleaning\ndel list_l","metadata":{"execution":{"iopub.status.busy":"2023-10-13T21:58:46.634467Z","iopub.execute_input":"2023-10-13T21:58:46.634873Z","iopub.status.idle":"2023-10-13T21:58:46.640103Z","shell.execute_reply.started":"2023-10-13T21:58:46.634842Z","shell.execute_reply":"2023-10-13T21:58:46.639002Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"# 4. Exploratory data analysis <a class=\"anchor\" id=\"chapter_4\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Short datasets summary <a class=\"anchor\" id=\"chapter_4_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"The dataset includes 3 unique authors (categories):\n* EAP, Edgar Allan Poe\n* HPL, Howard Phillips Lovecraft\n* MWS, Mary Wollstonecraft Shelley\n\nThe memory usage of datasets is measured in kilobytes. The approximate numbers are:\n* training data: 459 kB\n* testing data: 131 kB\n* sample data: 262.4 kB","metadata":{}},{"cell_type":"code","source":"def print_short_summary(name, data):\n    \"\"\"\n    Print data head, shape and info.\n    Args:\n        name (str): name of dataset\n        data (dataframe): dataset in a pd.DataFrame format\n    \"\"\"\n    print(name)\n    print('\\n1. Data head:')\n    print(data.head())\n    print('\\n2 Data shape: {}'.format(data.shape))\n    print('\\n3. Data info:')\n    data.info()\n    if 'text' in data.columns:\n        avg = np.mean(np.vectorize(len)(data['text']))\n        print('\\n4. Average number of characters per text: {:.0f}'.format(avg))","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:28:11.924969Z","iopub.execute_input":"2023-10-13T18:28:11.925388Z","iopub.status.idle":"2023-10-13T18:28:11.932702Z","shell.execute_reply.started":"2023-10-13T18:28:11.925359Z","shell.execute_reply":"2023-10-13T18:28:11.931386Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print_short_summary('Train data', train_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:28:12.694619Z","iopub.execute_input":"2023-10-13T18:28:12.695261Z","iopub.status.idle":"2023-10-13T18:28:12.744433Z","shell.execute_reply.started":"2023-10-13T18:28:12.69523Z","shell.execute_reply":"2023-10-13T18:28:12.742869Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Train data\n\n1. Data head:\n        id                                               text author\n0  id26305  This process, however, afforded me no means of...    EAP\n1  id17569  It never once occurred to me that the fumbling...    HPL\n2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n3  id27763  How lovely is spring As we looked from Windsor...    MWS\n4  id12958  Finding nothing else, not even gold, the Super...    HPL\n\n2 Data shape: (19579, 3)\n\n3. Data info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 19579 entries, 0 to 19578\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   id      19579 non-null  object\n 1   text    19579 non-null  object\n 2   author  19579 non-null  object\ndtypes: object(3)\nmemory usage: 459.0+ KB\n\n4. Average number of characters per text: 149\n","output_type":"stream"}]},{"cell_type":"code","source":"print_short_summary('Test data', test_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:28:13.345146Z","iopub.execute_input":"2023-10-13T18:28:13.345597Z","iopub.status.idle":"2023-10-13T18:28:13.36587Z","shell.execute_reply.started":"2023-10-13T18:28:13.345567Z","shell.execute_reply":"2023-10-13T18:28:13.364252Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Test data\n\n1. Data head:\n        id                                               text\n0  id02310  Still, as I urged our leaving Ireland with suc...\n1  id24541  If a fire wanted fanning, it could readily be ...\n2  id00134  And when they had broken down the frail door t...\n3  id27757  While I was thinking how I should possibly man...\n4  id04081  I am not sure to what limit his knowledge may ...\n\n2 Data shape: (8392, 2)\n\n3. Data info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8392 entries, 0 to 8391\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   id      8392 non-null   object\n 1   text    8392 non-null   object\ndtypes: object(2)\nmemory usage: 131.2+ KB\n\n4. Average number of characters per text: 148\n","output_type":"stream"}]},{"cell_type":"code","source":"print_short_summary('Sample data', sample_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:28:13.957906Z","iopub.execute_input":"2023-10-13T18:28:13.958349Z","iopub.status.idle":"2023-10-13T18:28:13.97905Z","shell.execute_reply.started":"2023-10-13T18:28:13.958316Z","shell.execute_reply":"2023-10-13T18:28:13.977416Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Sample data\n\n1. Data head:\n        id       EAP       HPL       MWS\n0  id02310  0.403494  0.287808  0.308698\n1  id24541  0.403494  0.287808  0.308698\n2  id00134  0.403494  0.287808  0.308698\n3  id27757  0.403494  0.287808  0.308698\n4  id04081  0.403494  0.287808  0.308698\n\n2 Data shape: (8392, 4)\n\n3. Data info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8392 entries, 0 to 8391\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   id      8392 non-null   object \n 1   EAP     8392 non-null   float64\n 2   HPL     8392 non-null   float64\n 3   MWS     8392 non-null   float64\ndtypes: float64(3), object(1)\nmemory usage: 262.4+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cleaning\ndel print_short_summary","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:28:15.112427Z","iopub.execute_input":"2023-10-13T18:28:15.112785Z","iopub.status.idle":"2023-10-13T18:28:15.118105Z","shell.execute_reply.started":"2023-10-13T18:28:15.112758Z","shell.execute_reply":"2023-10-13T18:28:15.116095Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Number of records per author <a class=\"anchor\" id=\"chapter_4_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"The dataset shows a slight imbalance in the number of texts per author. However, additional down/up-sampling is unnecessary for two reasons:\n1. Information loss when downsampling: removed samples can contain unique author's style which model wouldn't be able to catch\n2. Overfitting when upsampling: with added replicated samples model starts memorizing the duplicated examples instead of learning the underlying patterns","metadata":{}},{"cell_type":"code","source":"# Plot horizontal barplot of number of records per label\nplt.figure(figsize=(16, 9))\ntmp = train_data['author'].value_counts()\nsns.barplot(y=tmp.index.values, x=tmp.values, orient='h')\nplt.xlabel('Number of records')\nplt.ylabel('Author')\nplt.title('Number of records per author')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:29:30.605581Z","iopub.execute_input":"2023-10-13T18:29:30.606011Z","iopub.status.idle":"2023-10-13T18:29:30.898746Z","shell.execute_reply.started":"2023-10-13T18:29:30.605982Z","shell.execute_reply":"2023-10-13T18:29:30.897487Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1600x900 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Cleaning\ndel tmp","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:29:33.618082Z","iopub.execute_input":"2023-10-13T18:29:33.618627Z","iopub.status.idle":"2023-10-13T18:29:33.625483Z","shell.execute_reply.started":"2023-10-13T18:29:33.618576Z","shell.execute_reply":"2023-10-13T18:29:33.624133Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Word frequencies per author <a class=\"anchor\" id=\"chapter_4_3\"></a>","metadata":{}},{"cell_type":"markdown","source":"From the initial set of charts, it becomes evident that prepositions, articles, and pronouns dominate the frequency distribution. This dominance poses a challenge for the subsequent models as texts across authors share a similar pattern of short word usage. Considering these words as noise, we aim to eliminate this interference to provide models a better understanding of each author's unique word usage.","metadata":{}},{"cell_type":"code","source":"def plot_word_dist_author(labels, top_n_words = 10):\n    \"\"\"\n    Plot charts with word frequencies per author\n    Args:\n        labels: list of authors\n        top_n_words (opt): how many top words to plot in one chart\n    \"\"\"\n    n = len(labels)\n    \n    # Get default seaborn's palette to match colours with the previous chart\n    default_palette = sns.color_palette(\"deep\")\n    \n    # Initialize subplots with 1 row and n columns\n    fig, axes = plt.subplots(nrows=1, ncols=n, figsize=(16, 9))\n    \n    # Plot word count per author in the respective rows\n    for i in range(n):\n        col = i % n\n        indexes = train_data['author'] == labels[i]\n        w = train_data['text'][indexes].str.split(expand=True).unstack().value_counts()\n        l = w[:top_n_words]/np.sum(w)*100\n        axes[col].bar(l.index, l.values, color=default_palette[i])\n        axes[col].set_title(labels[i])\n        axes[col].set_xlabel('Words')\n        axes[col].set_ylabel('Percentage of total word count (%)')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:31:24.071274Z","iopub.execute_input":"2023-10-13T18:31:24.07196Z","iopub.status.idle":"2023-10-13T18:31:24.084004Z","shell.execute_reply.started":"2023-10-13T18:31:24.071886Z","shell.execute_reply":"2023-10-13T18:31:24.082406Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Plot word frequencies by author\nplot_word_dist_author(['EAP', 'MWS', 'HPL'])","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:31:25.412669Z","iopub.execute_input":"2023-10-13T18:31:25.413094Z","iopub.status.idle":"2023-10-13T18:31:27.639149Z","shell.execute_reply.started":"2023-10-13T18:31:25.413066Z","shell.execute_reply":"2023-10-13T18:31:27.637843Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1600x900 with 3 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Cleaning\ndel plot_word_dist_author","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:31:30.516712Z","iopub.execute_input":"2023-10-13T18:31:30.51714Z","iopub.status.idle":"2023-10-13T18:31:30.523078Z","shell.execute_reply.started":"2023-10-13T18:31:30.517112Z","shell.execute_reply":"2023-10-13T18:31:30.521299Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 5. Data preprocessing <a class=\"anchor\" id=\"chapter_5\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Text cleaning <a class=\"anchor\" id=\"chapter_5_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"Cleaning text via lemmatization, removing single-letter words, stopwords and digits reduces noise and irrelevant information. It should help models focus on important patterns and make training more efficient.","metadata":{}},{"cell_type":"code","source":"# Load english lemmas\nspacy_process = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n\n# Compile regex pattern\npattern = re.compile(r'\\b([a-zA-Z])\\b|\\d+|[.,!?()-:;]')\n\n# Set english stopwords such as \"the\", \"of\", \"and\", \"to\" etc.\nstop_words = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:35:54.606179Z","iopub.execute_input":"2023-10-13T18:35:54.60665Z","iopub.status.idle":"2023-10-13T18:35:55.482128Z","shell.execute_reply.started":"2023-10-13T18:35:54.606618Z","shell.execute_reply":"2023-10-13T18:35:55.481Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_processed_text(text):\n    \"\"\"\n    Return lemmatized text without single letters and digits.\n    Everything is in the lower case register.\n    Args:\n        text (str): text of an article\n    Returns:\n        text (str): cleand text\n    \"\"\"\n    # Convert to lowercase and remove digits, single letters\n    text = pattern.sub('', text.lower())\n    \n    # Get lemma tokens\n    lemmas = spacy_process(text)\n    lemmas = [token.lemma_ for token in lemmas if token.text not in stop_words]\n\n    # Join the words back into a string\n    text = ' '.join(lemmas)\n    \n    return text\n\ndef get_clean_text(texts):\n    \"\"\"\n    Return cleaned text.\n    Execution in parallel.\n    \n    Args:\n        texts: numpy array of string elements\n    Returns:\n        clean_texts: numpy array of cleaned string elements\n    \"\"\"\n    # Set up parallel tasks processing \n    with ProcessPoolExecutor() as executor:\n        clean_texts = list(executor.map(get_processed_text, texts))\n        \n    return np.array(clean_texts)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:35:58.4035Z","iopub.execute_input":"2023-10-13T18:35:58.403929Z","iopub.status.idle":"2023-10-13T18:35:58.412455Z","shell.execute_reply.started":"2023-10-13T18:35:58.403901Z","shell.execute_reply":"2023-10-13T18:35:58.410948Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Get cleaned train and test texts\ntrain_clean_data = get_clean_text(train_data['text'].values)\ntest_clean_data = get_clean_text(test_data['text'].values)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:36:01.30395Z","iopub.execute_input":"2023-10-13T18:36:01.30438Z","iopub.status.idle":"2023-10-13T18:37:09.956939Z","shell.execute_reply.started":"2023-10-13T18:36:01.304349Z","shell.execute_reply":"2023-10-13T18:37:09.955448Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Print an example of the cleaned text\ntrain_clean_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:38:28.312849Z","iopub.execute_input":"2023-10-13T18:38:28.313251Z","iopub.status.idle":"2023-10-13T18:38:28.321601Z","shell.execute_reply.started":"2023-10-13T18:38:28.313222Z","shell.execute_reply":"2023-10-13T18:38:28.320716Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'process however afford mean ascertain dimension dungeon   might make circuit return point whence   set without aware fact perfectly uniform seem wall'"},"metadata":{}}]},{"cell_type":"code","source":"# Cleaning\ndel spacy_process, pattern, stop_words\ndel get_clean_text, get_processed_text","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:38:32.146789Z","iopub.execute_input":"2023-10-13T18:38:32.147231Z","iopub.status.idle":"2023-10-13T18:38:32.156535Z","shell.execute_reply.started":"2023-10-13T18:38:32.1472Z","shell.execute_reply":"2023-10-13T18:38:32.154733Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 TF-IDF vectorization <a class=\"anchor\" id=\"chapter_5_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"When the TfidfVectorizer is applied to raw text, it converts the text data into a matrix of TF-IDF features. Specifically, the output is a sparse matrix representing the TF-IDF weights of the words in the input text.\n\n* sublinear_tf = True: this scaling often produces better results\n* ngram_range = (1, 2): with both unigrams and bigrams TF-IDF can capture more context and potentially improve the model's understanding of the text","metadata":{}},{"cell_type":"code","source":"# Create vectorizer to convert plain text into feature matrix\nvectorizer = TfidfVectorizer(sublinear_tf = True\n                             , ngram_range = (1,2)\n                             )\ntfidf_vect = vectorizer.fit(train_clean_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:42:14.50466Z","iopub.execute_input":"2023-10-13T18:42:14.505082Z","iopub.status.idle":"2023-10-13T18:42:16.067544Z","shell.execute_reply.started":"2023-10-13T18:42:14.505055Z","shell.execute_reply":"2023-10-13T18:42:16.06635Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Set training and testing data for the upcoming models\nX_train_tfidf = tfidf_vect.transform(train_clean_data)\nX_test_tfidf = tfidf_vect.transform(test_clean_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:42:19.504616Z","iopub.execute_input":"2023-10-13T18:42:19.504994Z","iopub.status.idle":"2023-10-13T18:42:20.775302Z","shell.execute_reply.started":"2023-10-13T18:42:19.504967Z","shell.execute_reply":"2023-10-13T18:42:20.774152Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"del vectorizer, test_data, train_clean_data, test_clean_data","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:42:26.023181Z","iopub.execute_input":"2023-10-13T18:42:26.023569Z","iopub.status.idle":"2023-10-13T18:42:26.073011Z","shell.execute_reply.started":"2023-10-13T18:42:26.023542Z","shell.execute_reply":"2023-10-13T18:42:26.071657Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Dimensionality reduction <a class=\"anchor\" id=\"chapter_5_3\"></a>","metadata":{}},{"cell_type":"markdown","source":"With TruncatedSVD we transform the TF-IDF matrix into a lower-dimensional representation. In doing so we aim to capture key information from the TF-IDF features.\n* n_components = 100: this is an arbitrary choice which allows the model training process faster without significant increase in its logloss","metadata":{}},{"cell_type":"code","source":"# Reduce dimensionality of TF-IDF matrices\nsvd = TruncatedSVD(n_components=100)\nX_train_svd = svd.fit_transform(X_train_tfidf)\nX_test_svd = svd.transform(X_test_tfidf)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T18:55:52.11634Z","iopub.execute_input":"2023-10-13T18:55:52.117137Z","iopub.status.idle":"2023-10-13T18:56:09.300072Z","shell.execute_reply.started":"2023-10-13T18:55:52.117078Z","shell.execute_reply":"2023-10-13T18:56:09.298205Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## 5.4 Standardization <a class=\"anchor\" id=\"chapter_5_4\"></a>","metadata":{}},{"cell_type":"markdown","source":"Since we're going to work with Logistic Regression, SVM, XGBoost, which use gradient descent for optimization, the standardization can be a good step in the data preprocessing. Standardizing TF-IDF features can help these models converge faster and might improve performance.\n\nMultinomial Naive Bayes and Random Forest are generally not affected by feature scales, thus no improvement in the final results is expected.\n\nIn order to fine-tune models in the next section we're going to use both standardized and non-standardized features in order to get the best scores under selected constraints.\n* with_mean = False: this setting preserves sparsity in text data, avoiding non-zero values and memory inefficiency caused by centering around the mean","metadata":{}},{"cell_type":"code","source":"# Standardize features without centering\nscaler = StandardScaler(with_mean = False)\nX_train_stand = scaler.fit_transform(X_train_tfidf)\nX_test_stand = scaler.fit_transform(X_test_tfidf)\n\nX_train_stand_svd = scaler.fit_transform(X_train_svd)\nX_test_stand_svd = scaler.fit_transform(X_test_svd)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T19:48:20.68419Z","iopub.execute_input":"2023-10-13T19:48:20.684649Z","iopub.status.idle":"2023-10-13T19:48:20.803813Z","shell.execute_reply.started":"2023-10-13T19:48:20.684615Z","shell.execute_reply":"2023-10-13T19:48:20.802347Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Cleaning\ndel scaler","metadata":{"execution":{"iopub.status.busy":"2023-10-13T19:48:27.11387Z","iopub.execute_input":"2023-10-13T19:48:27.114279Z","iopub.status.idle":"2023-10-13T19:48:27.120133Z","shell.execute_reply.started":"2023-10-13T19:48:27.114249Z","shell.execute_reply":"2023-10-13T19:48:27.118636Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## 5.5 Label encoding <a class=\"anchor\" id=\"chapter_5_5\"></a>","metadata":{}},{"cell_type":"markdown","source":"Label encoding works better in model training because it converts categorical labels into numerical representations, allowing algorithms to process them mathematically.","metadata":{}},{"cell_type":"code","source":"# Encode labels using OneHotEncoder\ndict_map = {'EAP':0, 'MWS':1, 'HPL':2}\ny_train = train_data['author'].map(dict_map).values","metadata":{"execution":{"iopub.status.busy":"2023-10-13T22:06:20.633545Z","iopub.execute_input":"2023-10-13T22:06:20.634014Z","iopub.status.idle":"2023-10-13T22:06:20.642699Z","shell.execute_reply.started":"2023-10-13T22:06:20.633978Z","shell.execute_reply":"2023-10-13T22:06:20.641344Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"# Cleaning\ndel label_encoder, train_data","metadata":{"execution":{"iopub.status.busy":"2023-10-13T19:06:54.465485Z","iopub.execute_input":"2023-10-13T19:06:54.46593Z","iopub.status.idle":"2023-10-13T19:06:54.476561Z","shell.execute_reply.started":"2023-10-13T19:06:54.465898Z","shell.execute_reply":"2023-10-13T19:06:54.475346Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# 6. Model architecture <a class=\"anchor\" id=\"chapter_6\"></a>","metadata":{}},{"cell_type":"markdown","source":"In this section we present 5 models tailored for notebook efficiency, all of which are generally considered to have decent predictive accuracy:\n* **Logistic Regression:**<br/>\nSimple, interpretable and efficient with sparse text data.\n* **Random Forest:**<br/>\nHandles non-linear relationships, robust to overfitting and capable of capturing complex patterns in text data.\n* **Multinomial Naive Bayes:**<br/>\nExtremely fast, efficient and works well with high-dimensional, sparse data.\n* **SVM:**<br/>\nEffective in handling non-linearity through kernels.\n* **XGBoost:**<br/>\nGenerally considered efficient and accurate with robust regularization techniques.","metadata":{}},{"cell_type":"markdown","source":"## 6.1 Logistic Regression <a class=\"anchor\" id=\"chapter_6_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"* class_weight = balanced: since we have slightly imbalanced dataset this setting helps the algorithm give more importance to minority class samples during training\n* C: inverse of regularization strength\n* solver: optimization algorithm used during training","metadata":{}},{"cell_type":"code","source":"# Set config for GridSearchCV\nconfig_logreg = {\n    'model': LogisticRegression()\n    , 'name': 'Log Reg'\n    , 'param_grid':\n    {\n        'class_weight': ['balanced']\n        , 'C': [0.5, 1.0, 1.5]\n        , 'solver': ['saga', 'lbfgs']\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-13T20:41:51.586942Z","iopub.execute_input":"2023-10-13T20:41:51.587424Z","iopub.status.idle":"2023-10-13T20:41:51.593888Z","shell.execute_reply.started":"2023-10-13T20:41:51.587389Z","shell.execute_reply":"2023-10-13T20:41:51.592873Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"## 6.2 Random Forest <a class=\"anchor\" id=\"chapter_6_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"* n_estimators: higher number of trees can improve the model's accuracy, but it also increases computational cost\n* max_depth: higher value leads to capture more complex patterns in the data, but may also result in overfitting","metadata":{}},{"cell_type":"code","source":"# Set config for GridSearchCV\nconfig_rf = {\n    'model': RandomForestClassifier()\n    , 'name': 'Random Forest'\n    , 'param_grid':\n    {\n        'n_estimators': [50, 75, 100]\n        , 'max_depth': [10, 20]\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-13T20:41:49.105127Z","iopub.execute_input":"2023-10-13T20:41:49.105537Z","iopub.status.idle":"2023-10-13T20:41:49.113169Z","shell.execute_reply.started":"2023-10-13T20:41:49.10551Z","shell.execute_reply":"2023-10-13T20:41:49.111624Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"## 6.3 Multinomial Naive Bayes <a class=\"anchor\" id=\"chapter_6_3\"></a>","metadata":{}},{"cell_type":"markdown","source":"* alpha: smoothing parameter that prevents zero probabilities in the computation, smalller values lead to underfitting, higher values - overfitting","metadata":{}},{"cell_type":"code","source":"# Set config for GridSearchCV\nconfig_nb = {\n    'model': MultinomialNB()\n    , 'name': 'Mult NB'\n    , 'param_grid':\n    {\n        'alpha': [0.001, 0.01, 0.1, 0.2, 0.4]\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-13T21:48:40.060478Z","iopub.execute_input":"2023-10-13T21:48:40.060951Z","iopub.status.idle":"2023-10-13T21:48:40.067411Z","shell.execute_reply.started":"2023-10-13T21:48:40.06092Z","shell.execute_reply":"2023-10-13T21:48:40.06609Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"## 6.4 SVM <a class=\"anchor\" id=\"chapter_6_4\"></a>","metadata":{}},{"cell_type":"markdown","source":"* class_weight = balanced: the same setting as in the Logistic Regression with similar reasoning\n* probability = True: allows the model to predict class probabilities which is useful in our case to calculate logloss\n* max_iter = 100: determines the maximum number of iterations taken for the solvers to converge\n* C: smaller values create a wider-margin decision boundary, potentially improving generalization, larger - fitting the training data more closely\n* kernel: function to transform the input data","metadata":{}},{"cell_type":"code","source":"# Set config for GridSearchCV\nconfig_svm = {\n    'model': SVC()\n    , 'name': 'SVM'\n    , 'param_grid':\n    {\n        'class_weight': ['balanced']\n        , 'probability': [True]\n        , 'max_iter': [100]\n        , 'C': [0.5, 1.0, 1.5]\n        , 'kernel': ['rbf', 'sigmoid']\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-13T20:41:38.405421Z","iopub.execute_input":"2023-10-13T20:41:38.406725Z","iopub.status.idle":"2023-10-13T20:41:38.413581Z","shell.execute_reply.started":"2023-10-13T20:41:38.406681Z","shell.execute_reply":"2023-10-13T20:41:38.412234Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"## 6.5 XGBoost <a class=\"anchor\" id=\"chapter_6_5\"></a>","metadata":{}},{"cell_type":"markdown","source":"* objective = 'multi:softmax': this setting ensures that the algorithm is optimized for predicting one of the n labels, which is 3 in our case\n* num_class = 3: number of unique authors\n* eval_metric = mlogloss: multi logloss, the specified metric used in a competition based on this dataset\n* n_estimators = 100: specifies the maximum number of boosting rounds\n* eta: learning rate, controls the step size shrinkage used in each boosting iteration\n* max_depth: the maximum depth of each tree in the boosting process","metadata":{}},{"cell_type":"code","source":"# Set config for GridSearchCV\nconfig_xgb = {\n    'model': xgb.XGBClassifier()\n    , 'name': 'XGBoost'\n    , 'param_grid':\n    {\n        'objective': ['multi:softmax']\n        , 'num_class': [3]\n        , 'eval_metric': ['mlogloss']\n        , 'n_estimators': [100]\n        , 'eta': [0.2, 0.3, 0.4]\n        , 'max_depth': [5, 7]\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-13T20:41:41.624777Z","iopub.execute_input":"2023-10-13T20:41:41.625252Z","iopub.status.idle":"2023-10-13T20:41:41.632059Z","shell.execute_reply.started":"2023-10-13T20:41:41.625219Z","shell.execute_reply":"2023-10-13T20:41:41.631065Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# 7. Model results <a class=\"anchor\" id=\"chapter_7\"></a>","metadata":{}},{"cell_type":"markdown","source":"Multinomial Naive Bayes stands out among our chosen models due to its handling of input data. It simply cannot process negative inputs. Therefore we opted for TF-IDF and standardized TF-IDF values for this model, since these inputs remain non-negative in contrast to the output of TruncatedSVD.\n\nThe final rankings are presented with model configurations sorted in ascending order based on their test logloss and runtime values. The following list showcases the models, starting from the best to worst performance:\n1. **Multinomial Naive Bayes:**<br/>\nMultinomial Naive Bayes excelled with the top performance observed at alpha = 0.01. Notably, its success was attributed to using non-standardized input, preserving raw frequency information essential for word count features. Standardization disrupted these patterns, hindering this model performance and scoring the last in the rankings.\n2. **XGBoost:**<br/>\nAlthough XGBoost secured the second position, it lagged behind notably in both logloss and runtime compared to the top performer. Intriguingly, standardizing the data had minimal impact on the algorithm's efficiency, highlighting its resilience to variations in input scaling. Adjusting the maximum number of rounds might have enhanced its performance, but it would have resulted in a significantly longer computation time.\n3. **Logistic Regression:**<br/>\nThough Logistic Regression scored higher logloss than XGBoost, it completely outperformed it terms of runtime. Despite its logloss being only marginally higher, this model processed results in a mere 0.4 seconds, a stark contrast to the 165 seconds of XGBoost. Due to its simplicity additional parameter tuning can further enhance its speed, but not necessarily translate into better scores.\n4. **Random Forest:**<br/>\nRandom Forest models performed surprisingly poor with worse runtime and train/test scores. While being generally robust additional feature engineering or hyperparameter tuning might have improved the model's speed and accuracy.\n5. **SVM:**<br/>\nThese set of models though resulted the last in test logloss, were twice as fast as Random Forest. However this speed advantage did not translate into improved accuracy, as their logloss exceeded 1. This indicates that the models might need more nuanced tuning, since they're very sensitive to the supoptimal choices.\n\nExamining the selected models based on the disparity between their train and test scores, Logistic Regression and SVM stood out with better generalization. In contrast, other algorithms displayed noticeable signs of overfitting.","metadata":{}},{"cell_type":"code","source":"def get_grid(config_model, X_train, y_train):\n    \"\"\"\n    Return grid of GridSearchCV results from selected models and their parameters.\n    Execution in parallel.\n    \n    Args:\n        config_model (dict): dictionary of model's parameters\n        X_train (ndarray): data to train\n        y_train (ndarray): data labels\n    Returns:\n        dict: a dictionary with the results from training via GridSeachCV\n    \"\"\"\n    # GridSearchCV utilizes all available CPU cores with n_jobs = -1.\n    grid = GridSearchCV(config_model['model']\n                        , config_model['param_grid']\n                        , return_train_score = True\n                        , scoring = 'neg_log_loss'\n                        , cv = 5\n                        , n_jobs = -1)\n\n    # Fit object to training data\n    grid = grid.fit(X_train, y_train)\n        \n\n    return grid\n\n\ndef get_model_results(model_name, grid_results, data_standardized):\n    \"\"\"\n    Return a dictionary of model results.\n    \n    Args:\n        model_name (str): name of a model\n        grid_results (dict): GridSearchCV dictionary of model results\n        data_standardized (1 or 0): data is stadardized\n    Returns:\n        dict: dictionary with updated columns\n    \"\"\"\n    runtime = grid_results['mean_fit_time'] + grid_results['mean_score_time']\n    model_results = {\n        'model': model_name\n        , 'params': grid_results['params']\n        , 'data_std': data_standardized\n        , 'mean_runtime (sec)': runtime\n        , 'mean_train_score (logloss)': -grid_results['mean_train_score']\n        , 'mean_test_score (logloss)': -grid_results['mean_test_score']\n    }\n    \n    return model_results\n\ndef get_table_results_sorted(list_dict):\n    \"\"\"\n    Convert list of dictionaries and sort by mean_test_score and mean_runtime.\n    \n    Args:\n        list_dict (list): list of dictionaries from GridSearchCV\n    Returns:\n        DataFrame: sorted dataframe by mean_test_score and mean_runtime\n    \"\"\"\n    table = [pd.DataFrame(results) for results in list_dict]   \n    table = pd.concat(table)\n    table = table.sort_values(by = ['mean_test_score (logloss)'\n                                  ,'mean_runtime (sec)']\n                        , ascending = [True, True])\n    \n    return table\n\ndef get_final_table_results(config_models, config_data):\n    \"\"\"\n    Return table with every trained model and its results from GridSearchCV.\n    \n    Args:\n        config_models (list): list of model configurations\n        confg_data (list): list of data configurations\n    Returns:\n        DataFrame: sorted dataframe by mean_test_score and mean_runtime\n    \"\"\"\n    n = len(config_models)\n    m = len(config_data)\n    table = []\n    for i in range(n):\n        for j in range(m):\n            print('model: {} of {} | data: {} of {}'.format(i+1,n,j+1,m))\n            grid = get_grid(config_models[i], config_data[j], y_train)\n            model_results = get_model_results(config_models[i]['name']\n                                              , grid.cv_results_\n                                             , j)\n            table.append(model_results)\n    \n    table = get_table_results_sorted(table)\n\n    return table","metadata":{"execution":{"iopub.status.busy":"2023-10-13T19:31:12.471224Z","iopub.execute_input":"2023-10-13T19:31:12.471632Z","iopub.status.idle":"2023-10-13T19:31:12.484265Z","shell.execute_reply.started":"2023-10-13T19:31:12.471604Z","shell.execute_reply":"2023-10-13T19:31:12.483016Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Create table of Multinomial Naive Bayes results\ntable_nb = get_final_table_results([config_nb], [X_train_tfidf, X_train_stand])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set list of models except Mult NB and non/standardized X_train\nconfig_models = [config_logreg, config_rf, config_svm, config_xgb]\nconfig_data = [X_train_svd, X_train_stand_svd]","metadata":{"execution":{"iopub.status.busy":"2023-10-13T22:20:58.018816Z","iopub.execute_input":"2023-10-13T22:20:58.020014Z","iopub.status.idle":"2023-10-13T22:20:58.025664Z","shell.execute_reply.started":"2023-10-13T22:20:58.019969Z","shell.execute_reply":"2023-10-13T22:20:58.024515Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"# Get table of every model except Mult NB\ntable_results = get_final_table_results(config_models, config_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate tables and print final rankings\ntable_results = get_table_results_sorted([table_results, table_nb])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print results table\ntable_results.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-14T00:42:47.499505Z","iopub.execute_input":"2023-10-14T00:42:47.49995Z","iopub.status.idle":"2023-10-14T00:42:47.535675Z","shell.execute_reply.started":"2023-10-14T00:42:47.499917Z","shell.execute_reply":"2023-10-14T00:42:47.534936Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"            model                                             params  \\\n0         Mult NB                                    {'alpha': 0.01}   \n1         Mult NB                                   {'alpha': 0.001}   \n2         Mult NB                                     {'alpha': 0.1}   \n3         Mult NB                                     {'alpha': 0.2}   \n4         Mult NB                                     {'alpha': 0.4}   \n5         XGBoost  {'eta': 0.2, 'eval_metric': 'mlogloss', 'max_d...   \n6         XGBoost  {'eta': 0.2, 'eval_metric': 'mlogloss', 'max_d...   \n7         XGBoost  {'eta': 0.3, 'eval_metric': 'mlogloss', 'max_d...   \n8         XGBoost  {'eta': 0.3, 'eval_metric': 'mlogloss', 'max_d...   \n9         XGBoost  {'eta': 0.2, 'eval_metric': 'mlogloss', 'max_d...   \n10        XGBoost  {'eta': 0.2, 'eval_metric': 'mlogloss', 'max_d...   \n11        XGBoost  {'eta': 0.4, 'eval_metric': 'mlogloss', 'max_d...   \n12        XGBoost  {'eta': 0.4, 'eval_metric': 'mlogloss', 'max_d...   \n13        Log Reg  {'C': 0.5, 'class_weight': 'balanced', 'solver...   \n14        Log Reg  {'C': 0.5, 'class_weight': 'balanced', 'solver...   \n15        Log Reg  {'C': 1.0, 'class_weight': 'balanced', 'solver...   \n16        Log Reg  {'C': 1.0, 'class_weight': 'balanced', 'solver...   \n17        Log Reg  {'C': 1.5, 'class_weight': 'balanced', 'solver...   \n18        Log Reg  {'C': 1.5, 'class_weight': 'balanced', 'solver...   \n19        XGBoost  {'eta': 0.3, 'eval_metric': 'mlogloss', 'max_d...   \n20        XGBoost  {'eta': 0.3, 'eval_metric': 'mlogloss', 'max_d...   \n21        Log Reg  {'C': 1.5, 'class_weight': 'balanced', 'solver...   \n22        Log Reg  {'C': 1.5, 'class_weight': 'balanced', 'solver...   \n23        Log Reg  {'C': 1.0, 'class_weight': 'balanced', 'solver...   \n24        Log Reg  {'C': 1.0, 'class_weight': 'balanced', 'solver...   \n25        XGBoost  {'eta': 0.4, 'eval_metric': 'mlogloss', 'max_d...   \n26        XGBoost  {'eta': 0.4, 'eval_metric': 'mlogloss', 'max_d...   \n27  Random Forest             {'max_depth': 20, 'n_estimators': 100}   \n28  Random Forest             {'max_depth': 20, 'n_estimators': 100}   \n29        Log Reg  {'C': 0.5, 'class_weight': 'balanced', 'solver...   \n30        Log Reg  {'C': 0.5, 'class_weight': 'balanced', 'solver...   \n31  Random Forest              {'max_depth': 20, 'n_estimators': 75}   \n32  Random Forest              {'max_depth': 20, 'n_estimators': 75}   \n33  Random Forest              {'max_depth': 20, 'n_estimators': 50}   \n34  Random Forest              {'max_depth': 20, 'n_estimators': 50}   \n35  Random Forest             {'max_depth': 10, 'n_estimators': 100}   \n36  Random Forest              {'max_depth': 10, 'n_estimators': 75}   \n37  Random Forest             {'max_depth': 10, 'n_estimators': 100}   \n38  Random Forest              {'max_depth': 10, 'n_estimators': 75}   \n39  Random Forest              {'max_depth': 10, 'n_estimators': 50}   \n40  Random Forest              {'max_depth': 10, 'n_estimators': 50}   \n41            SVM  {'C': 1.5, 'class_weight': 'balanced', 'kernel...   \n42            SVM  {'C': 1.0, 'class_weight': 'balanced', 'kernel...   \n43            SVM  {'C': 1.5, 'class_weight': 'balanced', 'kernel...   \n44            SVM  {'C': 1.0, 'class_weight': 'balanced', 'kernel...   \n45            SVM  {'C': 0.5, 'class_weight': 'balanced', 'kernel...   \n46            SVM  {'C': 0.5, 'class_weight': 'balanced', 'kernel...   \n47            SVM  {'C': 0.5, 'class_weight': 'balanced', 'kernel...   \n48            SVM  {'C': 0.5, 'class_weight': 'balanced', 'kernel...   \n49            SVM  {'C': 1.0, 'class_weight': 'balanced', 'kernel...   \n50            SVM  {'C': 1.5, 'class_weight': 'balanced', 'kernel...   \n51            SVM  {'C': 1.5, 'class_weight': 'balanced', 'kernel...   \n52            SVM  {'C': 1.0, 'class_weight': 'balanced', 'kernel...   \n53        Mult NB                                     {'alpha': 0.4}   \n54        Mult NB                                     {'alpha': 0.2}   \n55        Mult NB                                     {'alpha': 0.1}   \n56        Mult NB                                    {'alpha': 0.01}   \n57        Mult NB                                   {'alpha': 0.001}   \n\n    data_std  mean_runtime (sec)  mean_train_score (logloss)  \\\n0          0            0.099190                    0.007060   \n1          0            0.108816                    0.005063   \n2          0            0.101461                    0.040156   \n3          0            0.090844                    0.097879   \n4          0            0.084410                    0.218241   \n5          0          164.587107                    0.404302   \n6          1          165.384545                    0.404302   \n7          0          164.089526                    0.308546   \n8          1          164.793355                    0.308546   \n9          0          235.362629                    0.128991   \n10         1          238.627330                    0.128991   \n11         0          163.983702                    0.236945   \n12         1          163.312451                    0.237436   \n13         1            0.393199                    0.750263   \n14         1            1.645922                    0.750264   \n15         1            0.389355                    0.750266   \n16         1            1.651450                    0.750266   \n17         1            0.367503                    0.750266   \n18         1            1.577418                    0.750266   \n19         1          234.602349                    0.060153   \n20         0          235.536291                    0.059854   \n21         0            1.496343                    0.791807   \n22         0            1.217645                    0.791811   \n23         0            1.396362                    0.810406   \n24         0            0.756895                    0.810406   \n25         1          204.595798                    0.029212   \n26         0          209.104903                    0.029212   \n27         0           24.483069                    0.233975   \n28         1           24.390523                    0.233561   \n29         0            1.543344                    0.853645   \n30         0            0.566214                    0.853646   \n31         1           19.958266                    0.233715   \n32         0           19.962128                    0.234381   \n33         0           13.197720                    0.235049   \n34         1           13.148218                    0.235371   \n35         0           19.835769                    0.639785   \n36         1           15.035118                    0.639137   \n37         1           19.951341                    0.638681   \n38         0           15.076120                    0.638877   \n39         0            9.843235                    0.640321   \n40         1            9.934274                    0.641357   \n41         0            6.463472                    1.046782   \n42         0            7.358525                    1.047540   \n43         1            6.988036                    1.073289   \n44         1            8.204730                    1.106145   \n45         0            7.663009                    1.129095   \n46         0            7.628360                    1.171711   \n47         1            8.026069                    1.213661   \n48         1            7.783670                    1.234288   \n49         0            7.265167                    1.262414   \n50         1            7.309726                    1.262104   \n51         0            7.519510                    1.284587   \n52         1            7.464370                    1.288533   \n53         1            0.073109                    0.031737   \n54         1            0.078562                    0.031742   \n55         1            0.078848                    0.031744   \n56         1            0.088603                    0.031747   \n57         1            0.094084                    0.031747   \n\n    mean_test_score (logloss)  \n0                    0.452783  \n1                    0.476987  \n2                    0.523184  \n3                    0.577759  \n4                    0.648070  \n5                    0.744850  \n6                    0.744850  \n7                    0.749213  \n8                    0.749213  \n9                    0.760204  \n10                   0.760205  \n11                   0.760511  \n12                   0.761905  \n13                   0.765095  \n14                   0.765096  \n15                   0.765114  \n16                   0.765114  \n17                   0.765120  \n18                   0.765120  \n19                   0.794921  \n20                   0.795098  \n21                   0.799606  \n22                   0.799612  \n23                   0.817080  \n24                   0.817082  \n25                   0.839349  \n26                   0.839349  \n27                   0.856727  \n28                   0.857866  \n29                   0.858523  \n30                   0.858526  \n31                   0.860118  \n32                   0.860595  \n33                   0.865464  \n34                   0.865847  \n35                   0.871888  \n36                   0.872276  \n37                   0.872298  \n38                   0.872536  \n39                   0.873226  \n40                   0.874609  \n41                   1.042692  \n42                   1.045133  \n43                   1.071005  \n44                   1.103482  \n45                   1.125866  \n46                   1.171240  \n47                   1.209578  \n48                   1.233772  \n49                   1.262093  \n50                   1.262249  \n51                   1.284277  \n52                   1.287908  \n53                   8.594115  \n54                   8.613634  \n55                   8.644568  \n56                   8.766650  \n57                   8.842332  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>params</th>\n      <th>data_std</th>\n      <th>mean_runtime (sec)</th>\n      <th>mean_train_score (logloss)</th>\n      <th>mean_test_score (logloss)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.01}</td>\n      <td>0</td>\n      <td>0.099190</td>\n      <td>0.007060</td>\n      <td>0.452783</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.001}</td>\n      <td>0</td>\n      <td>0.108816</td>\n      <td>0.005063</td>\n      <td>0.476987</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.1}</td>\n      <td>0</td>\n      <td>0.101461</td>\n      <td>0.040156</td>\n      <td>0.523184</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.2}</td>\n      <td>0</td>\n      <td>0.090844</td>\n      <td>0.097879</td>\n      <td>0.577759</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.4}</td>\n      <td>0</td>\n      <td>0.084410</td>\n      <td>0.218241</td>\n      <td>0.648070</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.2, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>0</td>\n      <td>164.587107</td>\n      <td>0.404302</td>\n      <td>0.744850</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.2, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>1</td>\n      <td>165.384545</td>\n      <td>0.404302</td>\n      <td>0.744850</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.3, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>0</td>\n      <td>164.089526</td>\n      <td>0.308546</td>\n      <td>0.749213</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.3, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>1</td>\n      <td>164.793355</td>\n      <td>0.308546</td>\n      <td>0.749213</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.2, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>0</td>\n      <td>235.362629</td>\n      <td>0.128991</td>\n      <td>0.760204</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.2, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>1</td>\n      <td>238.627330</td>\n      <td>0.128991</td>\n      <td>0.760205</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.4, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>0</td>\n      <td>163.983702</td>\n      <td>0.236945</td>\n      <td>0.760511</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.4, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>1</td>\n      <td>163.312451</td>\n      <td>0.237436</td>\n      <td>0.761905</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Log Reg</td>\n      <td>{'C': 0.5, 'class_weight': 'balanced', 'solver...</td>\n      <td>1</td>\n      <td>0.393199</td>\n      <td>0.750263</td>\n      <td>0.765095</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Log Reg</td>\n      <td>{'C': 0.5, 'class_weight': 'balanced', 'solver...</td>\n      <td>1</td>\n      <td>1.645922</td>\n      <td>0.750264</td>\n      <td>0.765096</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Log Reg</td>\n      <td>{'C': 1.0, 'class_weight': 'balanced', 'solver...</td>\n      <td>1</td>\n      <td>0.389355</td>\n      <td>0.750266</td>\n      <td>0.765114</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Log Reg</td>\n      <td>{'C': 1.0, 'class_weight': 'balanced', 'solver...</td>\n      <td>1</td>\n      <td>1.651450</td>\n      <td>0.750266</td>\n      <td>0.765114</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Log Reg</td>\n      <td>{'C': 1.5, 'class_weight': 'balanced', 'solver...</td>\n      <td>1</td>\n      <td>0.367503</td>\n      <td>0.750266</td>\n      <td>0.765120</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Log Reg</td>\n      <td>{'C': 1.5, 'class_weight': 'balanced', 'solver...</td>\n      <td>1</td>\n      <td>1.577418</td>\n      <td>0.750266</td>\n      <td>0.765120</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.3, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>1</td>\n      <td>234.602349</td>\n      <td>0.060153</td>\n      <td>0.794921</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.3, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>0</td>\n      <td>235.536291</td>\n      <td>0.059854</td>\n      <td>0.795098</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Log Reg</td>\n      <td>{'C': 1.5, 'class_weight': 'balanced', 'solver...</td>\n      <td>0</td>\n      <td>1.496343</td>\n      <td>0.791807</td>\n      <td>0.799606</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Log Reg</td>\n      <td>{'C': 1.5, 'class_weight': 'balanced', 'solver...</td>\n      <td>0</td>\n      <td>1.217645</td>\n      <td>0.791811</td>\n      <td>0.799612</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Log Reg</td>\n      <td>{'C': 1.0, 'class_weight': 'balanced', 'solver...</td>\n      <td>0</td>\n      <td>1.396362</td>\n      <td>0.810406</td>\n      <td>0.817080</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Log Reg</td>\n      <td>{'C': 1.0, 'class_weight': 'balanced', 'solver...</td>\n      <td>0</td>\n      <td>0.756895</td>\n      <td>0.810406</td>\n      <td>0.817082</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.4, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>1</td>\n      <td>204.595798</td>\n      <td>0.029212</td>\n      <td>0.839349</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>XGBoost</td>\n      <td>{'eta': 0.4, 'eval_metric': 'mlogloss', 'max_d...</td>\n      <td>0</td>\n      <td>209.104903</td>\n      <td>0.029212</td>\n      <td>0.839349</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n      <td>0</td>\n      <td>24.483069</td>\n      <td>0.233975</td>\n      <td>0.856727</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n      <td>1</td>\n      <td>24.390523</td>\n      <td>0.233561</td>\n      <td>0.857866</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Log Reg</td>\n      <td>{'C': 0.5, 'class_weight': 'balanced', 'solver...</td>\n      <td>0</td>\n      <td>1.543344</td>\n      <td>0.853645</td>\n      <td>0.858523</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Log Reg</td>\n      <td>{'C': 0.5, 'class_weight': 'balanced', 'solver...</td>\n      <td>0</td>\n      <td>0.566214</td>\n      <td>0.853646</td>\n      <td>0.858526</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 20, 'n_estimators': 75}</td>\n      <td>1</td>\n      <td>19.958266</td>\n      <td>0.233715</td>\n      <td>0.860118</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 20, 'n_estimators': 75}</td>\n      <td>0</td>\n      <td>19.962128</td>\n      <td>0.234381</td>\n      <td>0.860595</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 20, 'n_estimators': 50}</td>\n      <td>0</td>\n      <td>13.197720</td>\n      <td>0.235049</td>\n      <td>0.865464</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 20, 'n_estimators': 50}</td>\n      <td>1</td>\n      <td>13.148218</td>\n      <td>0.235371</td>\n      <td>0.865847</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n      <td>0</td>\n      <td>19.835769</td>\n      <td>0.639785</td>\n      <td>0.871888</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 10, 'n_estimators': 75}</td>\n      <td>1</td>\n      <td>15.035118</td>\n      <td>0.639137</td>\n      <td>0.872276</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n      <td>1</td>\n      <td>19.951341</td>\n      <td>0.638681</td>\n      <td>0.872298</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 10, 'n_estimators': 75}</td>\n      <td>0</td>\n      <td>15.076120</td>\n      <td>0.638877</td>\n      <td>0.872536</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n      <td>0</td>\n      <td>9.843235</td>\n      <td>0.640321</td>\n      <td>0.873226</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Random Forest</td>\n      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n      <td>1</td>\n      <td>9.934274</td>\n      <td>0.641357</td>\n      <td>0.874609</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>SVM</td>\n      <td>{'C': 1.5, 'class_weight': 'balanced', 'kernel...</td>\n      <td>0</td>\n      <td>6.463472</td>\n      <td>1.046782</td>\n      <td>1.042692</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>SVM</td>\n      <td>{'C': 1.0, 'class_weight': 'balanced', 'kernel...</td>\n      <td>0</td>\n      <td>7.358525</td>\n      <td>1.047540</td>\n      <td>1.045133</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>SVM</td>\n      <td>{'C': 1.5, 'class_weight': 'balanced', 'kernel...</td>\n      <td>1</td>\n      <td>6.988036</td>\n      <td>1.073289</td>\n      <td>1.071005</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>SVM</td>\n      <td>{'C': 1.0, 'class_weight': 'balanced', 'kernel...</td>\n      <td>1</td>\n      <td>8.204730</td>\n      <td>1.106145</td>\n      <td>1.103482</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>SVM</td>\n      <td>{'C': 0.5, 'class_weight': 'balanced', 'kernel...</td>\n      <td>0</td>\n      <td>7.663009</td>\n      <td>1.129095</td>\n      <td>1.125866</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>SVM</td>\n      <td>{'C': 0.5, 'class_weight': 'balanced', 'kernel...</td>\n      <td>0</td>\n      <td>7.628360</td>\n      <td>1.171711</td>\n      <td>1.171240</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>SVM</td>\n      <td>{'C': 0.5, 'class_weight': 'balanced', 'kernel...</td>\n      <td>1</td>\n      <td>8.026069</td>\n      <td>1.213661</td>\n      <td>1.209578</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>SVM</td>\n      <td>{'C': 0.5, 'class_weight': 'balanced', 'kernel...</td>\n      <td>1</td>\n      <td>7.783670</td>\n      <td>1.234288</td>\n      <td>1.233772</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>SVM</td>\n      <td>{'C': 1.0, 'class_weight': 'balanced', 'kernel...</td>\n      <td>0</td>\n      <td>7.265167</td>\n      <td>1.262414</td>\n      <td>1.262093</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>SVM</td>\n      <td>{'C': 1.5, 'class_weight': 'balanced', 'kernel...</td>\n      <td>1</td>\n      <td>7.309726</td>\n      <td>1.262104</td>\n      <td>1.262249</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>SVM</td>\n      <td>{'C': 1.5, 'class_weight': 'balanced', 'kernel...</td>\n      <td>0</td>\n      <td>7.519510</td>\n      <td>1.284587</td>\n      <td>1.284277</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>SVM</td>\n      <td>{'C': 1.0, 'class_weight': 'balanced', 'kernel...</td>\n      <td>1</td>\n      <td>7.464370</td>\n      <td>1.288533</td>\n      <td>1.287908</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.4}</td>\n      <td>1</td>\n      <td>0.073109</td>\n      <td>0.031737</td>\n      <td>8.594115</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.2}</td>\n      <td>1</td>\n      <td>0.078562</td>\n      <td>0.031742</td>\n      <td>8.613634</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.1}</td>\n      <td>1</td>\n      <td>0.078848</td>\n      <td>0.031744</td>\n      <td>8.644568</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.01}</td>\n      <td>1</td>\n      <td>0.088603</td>\n      <td>0.031747</td>\n      <td>8.766650</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Mult NB</td>\n      <td>{'alpha': 0.001}</td>\n      <td>1</td>\n      <td>0.094084</td>\n      <td>0.031747</td>\n      <td>8.842332</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Cleaning\ndel config_models, config_data, table_results, table_nb\ndel get_grid, get_model_results, get_table_results_sorted, get_final_table_results","metadata":{"execution":{"iopub.status.busy":"2023-10-11T18:01:28.163062Z","iopub.execute_input":"2023-10-11T18:01:28.164378Z","iopub.status.idle":"2023-10-11T18:01:28.184416Z","shell.execute_reply.started":"2023-10-11T18:01:28.164305Z","shell.execute_reply":"2023-10-11T18:01:28.18346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Submission results <a class=\"anchor\" id=\"chapter_8\"></a>","metadata":{}},{"cell_type":"markdown","source":"### Public score: 0.41209","metadata":{}},{"cell_type":"code","source":"# Fit top performance model\nmodel = MultinomialNB(alpha = 0.01).fit(X_train_tfidf, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T23:31:52.622625Z","iopub.execute_input":"2023-10-13T23:31:52.624632Z","iopub.status.idle":"2023-10-13T23:31:52.671593Z","shell.execute_reply.started":"2023-10-13T23:31:52.624579Z","shell.execute_reply":"2023-10-13T23:31:52.670448Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"# Get predicted probabilities of classes\nresults = model.predict_proba(X_test_tfidf)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T23:32:02.912974Z","iopub.execute_input":"2023-10-13T23:32:02.913391Z","iopub.status.idle":"2023-10-13T23:32:02.935071Z","shell.execute_reply.started":"2023-10-13T23:32:02.913364Z","shell.execute_reply":"2023-10-13T23:32:02.933786Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"# Create submission talbe\ntable_submis = pd.DataFrame(results, columns=['EAP', 'MWS', 'HPL'])\ntable_submis['id'] = sample_data['id']","metadata":{"execution":{"iopub.status.busy":"2023-10-13T23:32:57.876512Z","iopub.execute_input":"2023-10-13T23:32:57.876982Z","iopub.status.idle":"2023-10-13T23:32:57.887716Z","shell.execute_reply.started":"2023-10-13T23:32:57.876949Z","shell.execute_reply":"2023-10-13T23:32:57.886106Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"# Print submission table\ntable_submis[['id','EAP','HPL','MWS']]","metadata":{"execution":{"iopub.status.busy":"2023-10-13T23:33:01.619614Z","iopub.execute_input":"2023-10-13T23:33:01.620305Z","iopub.status.idle":"2023-10-13T23:33:01.639464Z","shell.execute_reply.started":"2023-10-13T23:33:01.620271Z","shell.execute_reply":"2023-10-13T23:33:01.637997Z"},"trusted":true},"execution_count":126,"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"           id       EAP       HPL       MWS\n0     id02310  0.082737  0.012839  0.904424\n1     id24541  0.981698  0.005675  0.012627\n2     id00134  0.175292  0.818827  0.005881\n3     id27757  0.973328  0.026642  0.000030\n4     id04081  0.838934  0.092796  0.068270\n...       ...       ...       ...       ...\n8387  id11749  0.589244  0.085558  0.325198\n8388  id10526  0.089651  0.082103  0.828247\n8389  id13477  0.999920  0.000039  0.000041\n8390  id13761  0.127073  0.003818  0.869110\n8391  id04282  0.116873  0.882643  0.000484\n\n[8392 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>EAP</th>\n      <th>HPL</th>\n      <th>MWS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id02310</td>\n      <td>0.082737</td>\n      <td>0.012839</td>\n      <td>0.904424</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id24541</td>\n      <td>0.981698</td>\n      <td>0.005675</td>\n      <td>0.012627</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id00134</td>\n      <td>0.175292</td>\n      <td>0.818827</td>\n      <td>0.005881</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id27757</td>\n      <td>0.973328</td>\n      <td>0.026642</td>\n      <td>0.000030</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id04081</td>\n      <td>0.838934</td>\n      <td>0.092796</td>\n      <td>0.068270</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8387</th>\n      <td>id11749</td>\n      <td>0.589244</td>\n      <td>0.085558</td>\n      <td>0.325198</td>\n    </tr>\n    <tr>\n      <th>8388</th>\n      <td>id10526</td>\n      <td>0.089651</td>\n      <td>0.082103</td>\n      <td>0.828247</td>\n    </tr>\n    <tr>\n      <th>8389</th>\n      <td>id13477</td>\n      <td>0.999920</td>\n      <td>0.000039</td>\n      <td>0.000041</td>\n    </tr>\n    <tr>\n      <th>8390</th>\n      <td>id13761</td>\n      <td>0.127073</td>\n      <td>0.003818</td>\n      <td>0.869110</td>\n    </tr>\n    <tr>\n      <th>8391</th>\n      <td>id04282</td>\n      <td>0.116873</td>\n      <td>0.882643</td>\n      <td>0.000484</td>\n    </tr>\n  </tbody>\n</table>\n<p>8392 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Make submission\ntable_submis.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T23:33:42.413551Z","iopub.execute_input":"2023-10-13T23:33:42.414038Z","iopub.status.idle":"2023-10-13T23:33:42.478959Z","shell.execute_reply.started":"2023-10-13T23:33:42.414001Z","shell.execute_reply":"2023-10-13T23:33:42.478012Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"# Cleaning\ndel model, results, table_submis","metadata":{"execution":{"iopub.status.busy":"2023-10-11T18:01:34.090668Z","iopub.execute_input":"2023-10-11T18:01:34.09112Z","iopub.status.idle":"2023-10-11T18:01:34.106293Z","shell.execute_reply.started":"2023-10-11T18:01:34.091084Z","shell.execute_reply":"2023-10-11T18:01:34.105045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Conclusion <a class=\"anchor\" id=\"chapter_9\"></a>","metadata":{}},{"cell_type":"markdown","source":"In this study, five distinct models were tested within constrained computational resources, leading to the following insights:\n\n1. **Logistic Regression:**<br/>\nSlightly higher logloss than XGBoost but excelled in runtime due to its simplicity. Further parameter tuning could enhance speed however doesn't guarantee improved scores.\n2. **Random Forest:**<br/>\nPerformed below expectations, suggesting potential gains through feature engineering or hyperparameter adjustments for better speed and accuracy.\n3. **Multinomial Naive Bayes:**<br/>\nExcelled at alpha = 0.01, leveraging non-standardized input. Standardization disrupted patterns, resulting in the lowest ranking.\n4. **SVM:**<br/>\nDespite being twice as fast as Random Forest, its speed advantage did not boost accuracy. Nuanced tuning is essential, given the models' sensitivity to suboptimal choices.\n5. **XGBoost:**<br/>\nSecured the second position, demonstrating resilience to input scaling variations. Adjusting rounds might improve performance, albeit at the cost of increased computation time.\n\nAdditionally, considering the disparity between train and test scores, Logistic Regression and SVM exhibited superior generalization. In contrast, other models displayed prominent signs of overfitting. These findings underscore the delicate balance between model complexity, efficiency, and accuracy, highlighting areas for further optimization.","metadata":{}},{"cell_type":"markdown","source":"# 10. References <a class=\"anchor\" id=\"chapter_10\"></a>","metadata":{}},{"cell_type":"markdown","source":"* Meg Risdal, Rachael Tatman. (2017). Spooky Author Identification. Kaggle.<br/>\nhttps://kaggle.com/competitions/spooky-author-identification\n* BBC News Classification: Matrix Factorization vs Supervised Learning<br/>\nhttps://www.kaggle.com/code/jaymanvirk/matrix-factorization-nmf-vs-supervised-learning\n* Scikit-learn Supervised learning<br/>\nhttps://scikit-learn.org/stable/supervised_learning.html\n* XGBoost Parameters<br/>\nhttps://xgboost.readthedocs.io/en/stable/parameter.html\n* Launching parallel tasks<br/>\nhttps://docs.python.org/3/library/concurrent.futures.html","metadata":{}}]}